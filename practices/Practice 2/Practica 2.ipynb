{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import cv2\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraccion de keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración de MediaPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
    "PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "options = PoseLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path='pose_landmarker_heavy.task'),\n",
    "    running_mode=VisionRunningMode.VIDEO,\n",
    "    output_segmentation_masks=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_video(video_path, annotated_image):\n",
    "    \"\"\"\n",
    "    Muestra un video con anotaciones en una ventana y permite al usuario interrumpir el procesamiento.\n",
    "\n",
    "    Esta función muestra un frame anotado de un video en una ventana con el título basado en el nombre del archivo de video.\n",
    "    El usuario puede interrumpir el procesamiento del video presionando la tecla 'q'.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    video_path : str\n",
    "        Ruta del archivo de video que se está procesando.\n",
    "    annotated_image : numpy.ndarray\n",
    "        Imagen anotada (frame del video) que se mostrará en la ventana.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    bool\n",
    "        Retorna `True` si el usuario interrumpe el procesamiento presionando 'q', de lo contrario retorna `False`.\n",
    "\n",
    "    Notas\n",
    "    -----\n",
    "    Esta función utiliza OpenCV para mostrar la imagen y capturar la entrada del usuario. La ventana se actualiza\n",
    "    continuamente mientras se procesa el video.\n",
    "\n",
    "    Ejemplos\n",
    "    --------\n",
    "    >>> display_video(\"video.mp4\", frame_anotado)\n",
    "    False  # El procesamiento continúa\n",
    "    >>> display_video(\"video.mp4\", frame_anotado)\n",
    "    True   # El usuario presionó 'q' para interrumpir el procesamiento\n",
    "    \"\"\"\n",
    "    \n",
    "    cv2.imshow(f\"Video: {os.path.basename(video_path)}\", annotated_image)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        print(f\"Procesamiento de '{video_path}' interrumpido por el usuario.\")\n",
    "        return True  \n",
    "    return False  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(video_path, frame_skip=1, show_video=True):\n",
    "    \"\"\"\n",
    "    Extrae los keypoints (puntos clave) de un video utilizando un modelo de detección de pose.\n",
    "\n",
    "    Esta función procesa un video frame por frame, detecta los keypoints de la pose humana en cada frame\n",
    "    utilizando un modelo de detección de pose, y almacena los resultados en una lista. Además, permite\n",
    "    visualizar el video con los keypoints dibujados en tiempo real.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    video_path : str\n",
    "        Ruta del archivo de video que se procesará.\n",
    "    frame_skip : int, opcional\n",
    "        Número de frames a saltar entre cada procesamiento. Por defecto es 1 (sin saltar frames).\n",
    "    show_video : bool, opcional\n",
    "        Si es `True`, muestra el video con los keypoints dibujados en una ventana. Por defecto es `True`.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    keypoints_data : list\n",
    "        Lista de listas que contiene los keypoints detectados en cada frame. Cada frame contiene un\n",
    "        diccionario con las coordenadas (x, y, z) y la visibilidad de cada keypoint.\n",
    "    frame_count : int\n",
    "        Número total de frames procesados en el video.\n",
    "    fps : float\n",
    "        Tasa de frames por segundo (FPS) del video.\n",
    "\n",
    "    Notas\n",
    "    -----\n",
    "    - Si no se detectan keypoints en un frame, se rellena con diccionarios vacíos.\n",
    "    - El usuario puede interrumpir el procesamiento presionando la tecla 'q' durante la visualización.\n",
    "    - La función utiliza OpenCV para la captura de video y MediaPipe para la detección de pose.\n",
    "\n",
    "    Ejemplos\n",
    "    --------\n",
    "    >>> keypoints, count, fps, width, height = extract_keypoints(\"video.mp4\", frame_skip=2, show_video=True)\n",
    "    >>> print(len(keypoints))  # Número de frames procesados\n",
    "    >>> print(keypoints[0])     # Keypoints del primer frame\n",
    "    \"\"\"\n",
    "    \n",
    "    keypoints_data = []\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error al abrir: {video_path}\")\n",
    "        return None, 0, 0, 0\n",
    "\n",
    "    frame_count = 0\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_skip_counter = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_skip == 0:\n",
    "            frame_skip_counter += 1\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
    "\n",
    "            timestamp_ms = int(frame_count * (1000 / fps))\n",
    "            \n",
    "            landmarker = PoseLandmarker.create_from_options(options)\n",
    "            pose_landmarker_result = landmarker.detect_for_video(mp_image, timestamp_ms)\n",
    "\n",
    "            annotated_image = frame.copy()\n",
    "            frame_keypoints = []\n",
    "\n",
    "            if pose_landmarker_result.pose_landmarks:\n",
    "                for landmark in pose_landmarker_result.pose_landmarks[0]:\n",
    "                    frame_keypoints.append({\n",
    "                        'x': landmark.x,\n",
    "                        'y': landmark.y,\n",
    "                        'z': landmark.z,\n",
    "                        'visibility': landmark.visibility\n",
    "                    })\n",
    "\n",
    "                landmark_list = landmark_pb2.NormalizedLandmarkList()\n",
    "                for landmark in pose_landmarker_result.pose_landmarks[0]:\n",
    "                    pb2_landmark = landmark_pb2.NormalizedLandmark(\n",
    "                        x=landmark.x, y=landmark.y, z=landmark.z, visibility=landmark.visibility\n",
    "                    )\n",
    "                    landmark_list.landmark.append(pb2_landmark)\n",
    "\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    annotated_image,\n",
    "                    landmark_list,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2),\n",
    "                    mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2)\n",
    "                )\n",
    "            else:\n",
    "                frame_keypoints = [{} for _ in range(33)]\n",
    "\n",
    "            keypoints_data.append(frame_keypoints)\n",
    "\n",
    "            if show_video:\n",
    "                if display_video(video_path, annotated_image):\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    landmarker.close()\n",
    "                    return None, 0, 0, 0\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    landmarker.close()\n",
    "    print(f\"Video procesado: {video_path}\")\n",
    "    return keypoints_data, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_all_videos(dataset_path, output_json, show_videos=True):\n",
    "    \"\"\"\n",
    "    Procesa todos los videos en un directorio, extrae keypoints y guarda los resultados en un archivo JSON.\n",
    "\n",
    "    Esta función recorre todos los archivos de video en el directorio especificado, extrae los keypoints\n",
    "    de pose humana utilizando la función `extract_keypoints`, y almacena los resultados en un archivo JSON.\n",
    "    Los videos deben tener un formato de nombre específico para extraer información como el ID de la persona\n",
    "    y la etiqueta.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    dataset_path : str\n",
    "        Ruta del directorio que contiene los videos a procesar.\n",
    "    output_json : str\n",
    "        Ruta del archivo JSON de salida donde se guardarán los datos procesados.\n",
    "    show_videos : bool, opcional\n",
    "        Si es `True`, muestra los videos con los keypoints dibujados durante el procesamiento.\n",
    "        Por defecto es `True`.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    None\n",
    "        La función no retorna ningún valor, pero guarda los datos procesados en un archivo JSON.\n",
    "\n",
    "    Notas\n",
    "    -----\n",
    "    - Los videos deben tener un nombre en el formato: `person_id_*_label.ext` (por ejemplo, `001_xyz_walk.MOV`).\n",
    "    - Si un video no cumple con el formato de nombre, se omite y se muestra un mensaje de advertencia.\n",
    "    - Si el procesamiento de un video es interrumpido por el usuario, no se guarda su información.\n",
    "    - La función utiliza `extract_keypoints` para extraer los keypoints y OpenCV para la visualización.\n",
    "\n",
    "    Ejemplos\n",
    "    --------\n",
    "    >>> process_all_videos(\"videos/\", \"output.json\", show_videos=False)\n",
    "    Procesamiento completado. Todos los datos guardados en: output.json\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "\n",
    "    for video_file in os.listdir(dataset_path):\n",
    "        if video_file.endswith(('.MOV', '.mp4')):\n",
    "            video_path = os.path.join(dataset_path, video_file)\n",
    "\n",
    "            parts = video_file.split('_')\n",
    "            if len(parts) < 3:\n",
    "                print(f\"Nombre de archivo inválido: {video_file}. Saltando.\")\n",
    "                continue\n",
    "\n",
    "            person_id = parts[0]\n",
    "            label = parts[2].split('.')[0]\n",
    "\n",
    "            keypoints, fps, = extract_keypoints(video_path, frame_skip=5, show_video=show_videos)\n",
    "\n",
    "            if keypoints is not None and fps > 0:\n",
    "                data[video_file] = {\n",
    "                    \"keypoints\": keypoints,\n",
    "                    \"label\": label,\n",
    "                    \"person_id\": person_id\n",
    "                }\n",
    "            elif keypoints is None:\n",
    "                print(\"No se guarda la información del video por interrupción\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Error al procesar {video_path}. No se añaden datos al JSON.\")\n",
    "\n",
    "    with open(output_json, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    print(\"Procesamiento completado. Todos los datos guardados en:\", output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Ejercicio 01...\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S01_01_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S01_01_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S01_01_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S02_01_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S02_01_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S02_01_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S03_01_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S03_01_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S03_01_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S04_01_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S04_01_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S04_01_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S05_01_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S05_01_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S05_01_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S06_01_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S06_01_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S06_01_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S07_01_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S07_01_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S07_01_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S08_01_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S08_01_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S08_01_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S09_01_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S09_01_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S09_01_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S10_01_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S10_01_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 01\\S10_01_Parcial.MOV\n",
      "Procesamiento completado. Todos los datos guardados en: Ejercicio 01.json\n",
      "Procesando Ejercicio 02...\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S01_02_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S01_02_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S01_02_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S02_02_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S02_02_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S02_02_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S03_02_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S03_02_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S03_02_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S04_02_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S04_02_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S04_02_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S05_02_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S05_02_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S05_02_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S06_02_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S06_02_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S06_02_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S07_02_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S07_02_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S07_02_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S08_02_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S08_02_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S08_02_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S09_02_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S09_02_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S09_02_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S10_02_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S10_02_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 02\\S10_02_Parcial.MOV\n",
      "Procesamiento completado. Todos los datos guardados en: Ejercicio 02.json\n",
      "Procesando Ejercicio 03...\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S01_03_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S01_03_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S01_03_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S02_03_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S02_03_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S02_03_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S03_03_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S03_03_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S03_03_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S04_03_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S04_03_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S04_03_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S05_03_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S05_03_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S05_03_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S06_03_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S06_03_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S06_03_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S07_03_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S07_03_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S07_03_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S08_03_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S08_03_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S08_03_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S09_03_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S09_03_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S09_03_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S10_03_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S10_03_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 03\\S10_03_Parcial.MOV\n",
      "Procesamiento completado. Todos los datos guardados en: Ejercicio 03.json\n",
      "Procesando Ejercicio 04...\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S01_04_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S01_04_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S01_04_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S02_04_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S02_04_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S02_04_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S03_04_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S03_04_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S03_04_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S04_04_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S04_04_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S04_04_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S05_04_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S05_04_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S05_04_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S06_04_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S06_04_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S06_04_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S07_04_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S07_04_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S07_04_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S08_04_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S08_04_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S08_04_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S09_04_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S09_04_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S09_04_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S10_04_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S10_04_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 04\\S10_04_Parcial.MOV\n",
      "Procesamiento completado. Todos los datos guardados en: Ejercicio 04.json\n",
      "Procesando Ejercicio 05...\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S01_05_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S01_05_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S01_05_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S02_05_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S02_05_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S02_05_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S03_05_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S03_05_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S03_05_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S04_05_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S04_05_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S04_05_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S05_05_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S05_05_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S05_05_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S06_05_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S06_05_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S06_05_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S07_05_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S07_05_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S07_05_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S08_05_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S08_05_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S08_05_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S09_05_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S09_05_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S09_05_Parcial.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S10_05_Completo.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S10_05_Ninguno.MOV\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Ejercicio 05\\S10_05_Parcial.MOV\n",
      "Procesamiento completado. Todos los datos guardados en: Ejercicio 05.json\n"
     ]
    }
   ],
   "source": [
    "base_path = r'H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet'  \n",
    "for i in range(1, 6):  # Itera desde 1 hasta 5 \n",
    "    exercise_num = str(i).zfill(2)  # Formato \"01\", \"02\", ..., \"05\"\n",
    "    dataset_path = os.path.join(base_path, f'Ejercicio {exercise_num}')\n",
    "    output_json = f'Ejercicio {exercise_num}.json'\n",
    "\n",
    "    print(f\"Procesando Ejercicio {exercise_num}...\")\n",
    "\n",
    "    # Verifica si la carpeta del ejercicio existe\n",
    "    if not os.path.exists(dataset_path):\n",
    "        print(f\"ERROR: La carpeta '{dataset_path}' no existe. Saltando...\")\n",
    "        continue  # Pasa al siguiente ejercicio si la carpeta no existe\n",
    "\n",
    "    # Llama a tu función de procesamiento\n",
    "    process_all_videos(dataset_path, output_json, show_videos=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(p1, p2, p3):\n",
    "    \"\"\"Calcula el ángulo entre tres puntos usando la fórmula del coseno.\"\"\"\n",
    "    v1 = np.array(p1) - np.array(p2)\n",
    "    v2 = np.array(p3) - np.array(p2)\n",
    "\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    magnitudes = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "\n",
    "    if magnitudes == 0:\n",
    "        return 0.0\n",
    "\n",
    "    cosine_angle = dot_product / magnitudes\n",
    "    angle_rad = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "    return math.degrees(angle_rad)\n",
    "\n",
    "def extract_features(video_data):\n",
    "    \"\"\"Extrae features de los datos de video.\"\"\"\n",
    "    frames = video_data[\"keypoints\"]\n",
    "    if not frames:\n",
    "        return None\n",
    "\n",
    "    num_keypoints = len(frames[0])\n",
    "    features = []\n",
    "\n",
    "    for kp_index in range(num_keypoints):\n",
    "        x_vals, y_vals, z_vals = [], [], []\n",
    "        for frame in frames:\n",
    "            if kp_index < len(frame) and frame[kp_index]:\n",
    "                kp = frame[kp_index]\n",
    "                x_vals.append(kp['x'])\n",
    "                y_vals.append(kp['y'])\n",
    "                z_vals.append(kp['z'])\n",
    "\n",
    "        if not x_vals:\n",
    "            features.extend([0.0] * 8)\n",
    "            continue\n",
    "\n",
    "        range_x = max(x_vals) - min(x_vals)\n",
    "        range_y = max(y_vals) - min(y_vals)\n",
    "\n",
    "        angles = []\n",
    "        anglesMirror = []\n",
    "        if 24 < num_keypoints:\n",
    "            for i in range(1, len(frames) - 1):\n",
    "\n",
    "                if frames[i][24] and frames[i][12] and frames[i][16] and frames[i][23] and frames[i][11] and frames[i][15]:\n",
    "                    p24 = [frames[i][24]['x'], frames[i][24]['y']]\n",
    "                    p12 = [frames[i][12]['x'], frames[i][12]['y']]\n",
    "                    p16 = [frames[i][16]['x'], frames[i][16]['y']]                    \n",
    "                    p23 = [frames[i][23]['x'], frames[i][23]['y']]\n",
    "                    p11 = [frames[i][11]['x'], frames[i][11]['y']]\n",
    "                    p15 = [frames[i][15]['x'], frames[i][15]['y']]     \n",
    "\n",
    "                    angle = calculate_angle(p24, p12, p16)\n",
    "                    angleMirror = calculate_angle(p23, p11, p15)\n",
    "                    angles.append(angle)\n",
    "                    anglesMirror.append(angleMirror)\n",
    "\n",
    "        avg_angle = np.mean(angles) if angles else 0.0\n",
    "        std_angle = np.std(angles) if angles else 0.0\n",
    "        avg_anglesMirror = np.mean(anglesMirror) if anglesMirror else 0.0\n",
    "        std_anglesMirror = np.std(anglesMirror) if anglesMirror else 0.0\n",
    "\n",
    "        features.extend([range_x, range_y, std_angle, avg_angle, avg_anglesMirror, std_anglesMirror])\n",
    "\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models_loo(data, exercise_num):\n",
    "    X = []\n",
    "    y = []\n",
    "    video_names = []\n",
    "\n",
    "    for video_name, video_data in data.items():\n",
    "        feat = extract_features(video_data)\n",
    "        if feat is not None:\n",
    "            X.append(feat)\n",
    "            y.append(video_data[\"label\"])\n",
    "            video_names.append(video_name)\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # X = scaler.fit_transform(np.array(X))\n",
    "    # joblib.dump(scaler, 'scaler.pkl')\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    video_names = np.array(video_names)\n",
    "\n",
    "    loo = LeaveOneOut()\n",
    "    results = {}\n",
    "\n",
    "    # Modelos a evaluar\n",
    "    models = {\n",
    "        \"SVC\": SVC(kernel='poly', gamma='scale'),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=3),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(),\n",
    "        \"CatBoost\": CatBoostClassifier(verbose=0)\n",
    "    }\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        y_true_all = []\n",
    "        y_pred_all = []\n",
    "        predictions = []\n",
    "\n",
    "        for train_index, test_index in loo.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            video_name_test = video_names[test_index][0]\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_true_all.extend(y_test)\n",
    "            y_pred_all.extend(y_pred)\n",
    "            predictions.append((video_name_test, y_test[0], y_pred[0]))\n",
    "\n",
    "        report = classification_report(y_true_all, y_pred_all, output_dict=True)\n",
    "        accuracy = accuracy_score(y_true_all, y_pred_all)\n",
    "\n",
    "        results[model_name] = {\n",
    "            # \"classification_report\": report,\n",
    "            \"average_precision\": report['macro avg']['precision'],\n",
    "            \"average_recall\": report['macro avg']['recall'],\n",
    "            \"average_f1_score\": report['macro avg']['f1-score'],\n",
    "            \"accuracy\": accuracy,\n",
    "            # \"predictions\": predictions,\n",
    "        }\n",
    "\n",
    "        # Guardar el modelo\n",
    "        joblib.dump(model, f'modelo_{model_name.lower()}_{exercise_num}.pkl')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Ejercicio 01...\n",
      "{\n",
      "    \"SVC\": {\n",
      "        \"average_precision\": 0.9696969696969697,\n",
      "        \"average_recall\": 0.9666666666666667,\n",
      "        \"average_f1_score\": 0.9665831244778613,\n",
      "        \"accuracy\": 0.9666666666666667\n",
      "    },\n",
      "    \"KNN\": {\n",
      "        \"average_precision\": 1.0,\n",
      "        \"average_recall\": 1.0,\n",
      "        \"average_f1_score\": 1.0,\n",
      "        \"accuracy\": 1.0\n",
      "    },\n",
      "    \"DecisionTree\": {\n",
      "        \"average_precision\": 1.0,\n",
      "        \"average_recall\": 1.0,\n",
      "        \"average_f1_score\": 1.0,\n",
      "        \"accuracy\": 1.0\n",
      "    },\n",
      "    \"CatBoost\": {\n",
      "        \"average_precision\": 1.0,\n",
      "        \"average_recall\": 1.0,\n",
      "        \"average_f1_score\": 1.0,\n",
      "        \"accuracy\": 1.0\n",
      "    }\n",
      "}\n",
      "Procesando Ejercicio 02...\n",
      "{\n",
      "    \"SVC\": {\n",
      "        \"average_precision\": 0.9444444444444445,\n",
      "        \"average_recall\": 0.9333333333333332,\n",
      "        \"average_f1_score\": 0.9326599326599326,\n",
      "        \"accuracy\": 0.9333333333333333\n",
      "    },\n",
      "    \"KNN\": {\n",
      "        \"average_precision\": 1.0,\n",
      "        \"average_recall\": 1.0,\n",
      "        \"average_f1_score\": 1.0,\n",
      "        \"accuracy\": 1.0\n",
      "    },\n",
      "    \"DecisionTree\": {\n",
      "        \"average_precision\": 1.0,\n",
      "        \"average_recall\": 1.0,\n",
      "        \"average_f1_score\": 1.0,\n",
      "        \"accuracy\": 1.0\n",
      "    },\n",
      "    \"CatBoost\": {\n",
      "        \"average_precision\": 1.0,\n",
      "        \"average_recall\": 1.0,\n",
      "        \"average_f1_score\": 1.0,\n",
      "        \"accuracy\": 1.0\n",
      "    }\n",
      "}\n",
      "Procesando Ejercicio 03...\n",
      "{\n",
      "    \"SVC\": {\n",
      "        \"average_precision\": 0.0,\n",
      "        \"average_recall\": 0.0,\n",
      "        \"average_f1_score\": 0.0,\n",
      "        \"accuracy\": 0.0\n",
      "    },\n",
      "    \"KNN\": {\n",
      "        \"average_precision\": 0.08333333333333333,\n",
      "        \"average_recall\": 0.16666666666666666,\n",
      "        \"average_f1_score\": 0.1111111111111111,\n",
      "        \"accuracy\": 0.16666666666666666\n",
      "    },\n",
      "    \"DecisionTree\": {\n",
      "        \"average_precision\": 0.5113636363636364,\n",
      "        \"average_recall\": 0.5,\n",
      "        \"average_f1_score\": 0.5026455026455027,\n",
      "        \"accuracy\": 0.5\n",
      "    },\n",
      "    \"CatBoost\": {\n",
      "        \"average_precision\": 0.5936026936026936,\n",
      "        \"average_recall\": 0.6,\n",
      "        \"average_f1_score\": 0.595906432748538,\n",
      "        \"accuracy\": 0.6\n",
      "    }\n",
      "}\n",
      "Procesando Ejercicio 04...\n",
      "{\n",
      "    \"SVC\": {\n",
      "        \"average_precision\": 0.26666666666666666,\n",
      "        \"average_recall\": 0.26666666666666666,\n",
      "        \"average_f1_score\": 0.26666666666666666,\n",
      "        \"accuracy\": 0.26666666666666666\n",
      "    },\n",
      "    \"KNN\": {\n",
      "        \"average_precision\": 0.3865800865800866,\n",
      "        \"average_recall\": 0.3666666666666667,\n",
      "        \"average_f1_score\": 0.3626984126984127,\n",
      "        \"accuracy\": 0.36666666666666664\n",
      "    },\n",
      "    \"DecisionTree\": {\n",
      "        \"average_precision\": 0.9696969696969697,\n",
      "        \"average_recall\": 0.9666666666666667,\n",
      "        \"average_f1_score\": 0.9665831244778612,\n",
      "        \"accuracy\": 0.9666666666666667\n",
      "    },\n",
      "    \"CatBoost\": {\n",
      "        \"average_precision\": 0.9696969696969697,\n",
      "        \"average_recall\": 0.9666666666666667,\n",
      "        \"average_f1_score\": 0.9665831244778612,\n",
      "        \"accuracy\": 0.9666666666666667\n",
      "    }\n",
      "}\n",
      "Procesando Ejercicio 05...\n",
      "{\n",
      "    \"SVC\": {\n",
      "        \"average_precision\": 0.0,\n",
      "        \"average_recall\": 0.0,\n",
      "        \"average_f1_score\": 0.0,\n",
      "        \"accuracy\": 0.0\n",
      "    },\n",
      "    \"KNN\": {\n",
      "        \"average_precision\": 0.0909090909090909,\n",
      "        \"average_recall\": 0.19999999999999998,\n",
      "        \"average_f1_score\": 0.125,\n",
      "        \"accuracy\": 0.2\n",
      "    },\n",
      "    \"DecisionTree\": {\n",
      "        \"average_precision\": 0.7831501831501831,\n",
      "        \"average_recall\": 0.7666666666666667,\n",
      "        \"average_f1_score\": 0.762830349531117,\n",
      "        \"accuracy\": 0.7666666666666667\n",
      "    },\n",
      "    \"CatBoost\": {\n",
      "        \"average_precision\": 0.6666666666666666,\n",
      "        \"average_recall\": 0.6666666666666666,\n",
      "        \"average_f1_score\": 0.6616161616161617,\n",
      "        \"accuracy\": 0.6666666666666666\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6): \n",
    "    exercise_num = str(i).zfill(2)  # Formato \"01\", \"02\", ..., \"05\"\n",
    "\n",
    "    with open(f'Ejercicio {exercise_num}.json', \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    print(f\"Procesando Ejercicio {exercise_num}...\")\n",
    "\n",
    "    # Llamar a la función de entrenamiento y evaluación\n",
    "    results = train_and_evaluate_models_loo(data, exercise_num)\n",
    "\n",
    "    # Imprimir los resultados formateados\n",
    "    if \"error\" in results:\n",
    "        print(results[\"error\"])  # Imprimir solo el mensaje de error\n",
    "    else:\n",
    "        print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validación externa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_videos(video_path, output_json, model_path, show_videos=False):\n",
    "    \"\"\"\n",
    "    Procesa videos en un directorio, realiza predicciones utilizando un modelo preentrenado y muestra los resultados.\n",
    "\n",
    "    Esta función procesa todos los videos en el directorio especificado, extrae características de los keypoints\n",
    "    detectados, carga un modelo preentrenado (SVC) y realiza predicciones sobre las etiquetas de los videos.\n",
    "    Los resultados se imprimen en la consola.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    video_path : str\n",
    "        Ruta del directorio que contiene los videos a procesar.\n",
    "    output_json : str\n",
    "        Ruta del archivo JSON donde se guardarán los datos procesados de los videos.\n",
    "    model_path : str\n",
    "        Ruta del archivo del modelo preentrenado (SVC) que se utilizará para las predicciones.\n",
    "    show_videos : bool, opcional\n",
    "        Si es `True`, muestra los videos con los keypoints dibujados durante el procesamiento.\n",
    "        Por defecto es `False`.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    None\n",
    "        La función no retorna ningún valor, pero imprime las predicciones en la consola.\n",
    "\n",
    "    Notas\n",
    "    -----\n",
    "    - La función utiliza `process_all_videos` para procesar los videos y guardar los datos en un archivo JSON.\n",
    "    - Se utiliza `extract_features` para extraer características de los keypoints detectados.\n",
    "    - El modelo preentrenado debe ser compatible con las características extraídas.\n",
    "    - Si el archivo JSON ya existe, se sobrescribirá con los nuevos datos.\n",
    "\n",
    "    Ejemplos\n",
    "    --------\n",
    "    >>> process_videos(new_video_path, output_json, 'modelo_entrenado.pkl', show_videos=False)\n",
    "    Video: video1.MOV\n",
    "    Etiqueta real: walk\n",
    "    Predicción: walk\n",
    "    \"\"\"\n",
    "    process_all_videos(video_path, output_json, show_videos=show_videos)\n",
    "\n",
    "    with open(output_json, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    for video_name, video_data in data.items():\n",
    "        X = extract_features(video_data)\n",
    "        X = np.array(X).reshape(1, -1)\n",
    "        y = np.array(video_data[\"label\"])\n",
    "\n",
    "        y_pred = model.predict(X)\n",
    "\n",
    "        print(f\"Video: {video_name}\")\n",
    "        print(\"Etiqueta real: \", y)\n",
    "        print(\"Predicción: \", y_pred, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Nueva carpeta\\S11_01_Parcial.mp4\n",
      "Video procesado: H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Nueva carpeta\\S12_01_Completo.mp4\n",
      "Procesamiento completado. Todos los datos guardados en: EjercicioExterno.json\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'modelo_catboost.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m output_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEjercicioExterno.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodelo_catboost.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m process_videos(new_video_path, output_json, model_path, show_videos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[22], line 45\u001b[0m, in \u001b[0;36mprocess_videos\u001b[1;34m(video_path, output_json, model_path, show_videos)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_json, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     43\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m---> 45\u001b[0m model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(model_path)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video_name, video_data \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     48\u001b[0m     X \u001b[38;5;241m=\u001b[39m extract_features(video_data)\n",
      "File \u001b[1;32mc:\\Users\\Jesus\\.conda\\envs\\DataScience\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'modelo_catboost.pkl'"
     ]
    }
   ],
   "source": [
    "new_video_path = r'H:\\Mi unidad\\CICESE\\2025-1\\CDSI2025Gortarez\\practices\\Practice 2\\DataSet\\Nueva carpeta'\n",
    "output_json = 'EjercicioExterno.json'\n",
    "model_path = 'modelo_catboost.pkl'\n",
    "\n",
    "process_videos(new_video_path, output_json, model_path, show_videos=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "La incorporación de landmarks específicos de las manos puede mejorar significativamente la precisión de los modelos en ejercicios que involucran movimientos manuales. Esto permite una detección más detallada y precisa de las posiciones y gestos de las manos.\n",
    "\n",
    "Implementar una técnica de escalado de datos en modo espejo puede ser beneficioso. Al reflejar los datos, podemos analizar ambos lados del cuerpo de una persona, lo que ayuda a identificar posibles variaciones o asimetrías en los movimientos. Esto podría proporcionar una visión más completa y equilibrada del rendimiento del ejercicio.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
