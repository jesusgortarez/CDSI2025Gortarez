{"cells":[{"cell_type":"markdown","metadata":{"id":"YOGoqDCeMaZC"},"source":["Explorar las diferentes librerías en Python para el procesamiento de audio y aplicar 5 de ellas para el tratamiento de un audio, el cual puede ser un sonido generado artificialmente, una canción, voz grabada, etc.\n","No limitarse a las técnicas exploradas en clase."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ykjiKdNSMaZF"},"outputs":[],"source":["import os\n","import librosa\n","import numpy as np\n","import noisereduce as nr\n","from pydub import AudioSegment\n","from pydub.silence import detect_nonsilent"]},{"cell_type":"markdown","metadata":{"id":"n9Gt_RgSMaZH"},"source":["Convierte un archivo de audio al formato WAV o exporta un AudioSegment existente.\n","\n","Parámetros:\n","- input_file: str o AudioSegment\n","    Ruta al archivo de audio de entrada que se desea convertir, o un objeto AudioSegment.\n","- output_file: str\n","    Ruta donde se guardará el archivo de audio convertido en formato WAV."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"siVAsgpKMaZH"},"outputs":[],"source":["def convert_to_wav(input_file, output_file):\n","    if isinstance(input_file, str):\n","        audio = AudioSegment.from_file(input_file)\n","        print(f\"Convertido a WAV desde archivo: {input_file} a {output_file}\")\n","    elif isinstance(input_file, AudioSegment):\n","        audio = input_file\n","        print(f\"Exportado AudioSegment a WAV: {output_file}\")\n","    else:\n","        raise ValueError(\"input_file debe ser una ruta de archivo (str) o un objeto AudioSegment.\")\n","\n","    # Exportar el audio al formato WAV\n","    audio.export(output_file, format='wav')\n"]},{"cell_type":"markdown","metadata":{"id":"0388jsykMaZI"},"source":["Reduce el ruido de fondo en un archivo de audio.\n","\n","Parámetros de entrada:\n","- audio: AudioSegment\n","    Objeto que representa el audio al que se le quiere reducir el ruido.\n","\n","Salida:\n","- AudioSegment\n","    Objeto con el ruido reducido."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YK35dqE5MaZJ"},"outputs":[],"source":["def reduce_noise(audio):\n","    samples = np.array(audio.get_array_of_samples())\n","    reduced_noise = nr.reduce_noise(y=samples, sr=audio.frame_rate)\n","    reduced_audio = AudioSegment(\n","        reduced_noise.tobytes(),\n","        frame_rate=audio.frame_rate,\n","        sample_width=audio.sample_width,\n","        channels=audio.channels\n","    )\n","    print(\"Ruido reducido\")\n","    return reduced_audio"]},{"cell_type":"markdown","metadata":{"id":"zCl4TL3hMaZJ"},"source":["Elimina el silencio al inicio y al final de un objeto de audio y devuelve el objeto de audio procesado.\n","\n","Parámetros de entrada:\n","- audio: AudioSegment\n","    Objeto que representa el audio a procesar.\n","- silence_thresh: int, opcional\n","    Umbral de silencio en decibelios (dB). Por defecto es -50 dB.\n","- min_silence_len: int, opcional\n","    Longitud mínima de silencio en milisegundos para ser considerado como tal. Por defecto es 500 ms.\n","\n","Salida:\n","- AudioSegment\n","    Objeto con el silencio recortado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K4rmgyh4MaZJ"},"outputs":[],"source":["def trim_silence(audio, silence_thresh=-40, min_silence_len=1000):\n","    non_silent_ranges = detect_nonsilent(audio, min_silence_len=min_silence_len, silence_thresh=silence_thresh)\n","    if non_silent_ranges:\n","        start_trim = non_silent_ranges[0][0]\n","        end_trim = non_silent_ranges[-1][1]\n","        trimmed_audio = audio[start_trim:end_trim]\n","        print(\"Silencio recortado\")\n","    else:\n","        trimmed_audio = audio\n","        print(\"No se detectó silencio significativo\")\n","    return trimmed_audio"]},{"cell_type":"markdown","metadata":{"id":"whTGl-qnMaZK"},"source":["Elimina el silencio al inicio y al final de un objeto de audio y devuelve el objeto de audio procesado.\n","\n","Parámetros de entrada:\n","- audio: AudioSegment\n","    Objeto que representa el audio a procesar.\n","- silence_thresh: int, opcional\n","    Umbral de silencio en decibelios (dB). Por defecto es 50 dB.\n","\n","Salida:\n","- AudioSegment\n","    Objeto con el silencio recortado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lpajUP_BMaZK"},"outputs":[],"source":["def trim_silence_librosa(audio, silence_thresh=50):\n","    # Convertir AudioSegment a numpy array\n","    samples = np.array(audio.get_array_of_samples())\n","    sr = audio.frame_rate\n","\n","    # Usar librosa para detectar silencios\n","    non_silent_intervals = librosa.effects.split(samples, top_db=silence_thresh)\n","\n","    if len(non_silent_intervals) > 0:\n","        # Convertir índices de muestras a milisegundos\n","        start_trim = (non_silent_intervals[0][0] / sr) * 1000\n","        end_trim = (non_silent_intervals[-1][1] / sr) * 1000\n","        trimmed_audio = audio[start_trim:end_trim]\n","        print(\"Silencio recortado\")\n","    else:\n","        trimmed_audio = audio\n","        print(\"No se detectó silencio significativo\")\n","\n","    return trimmed_audio"]},{"cell_type":"markdown","metadata":{"id":"yPBk9nc7MaZK"},"source":["Normaliza el volumen de un objeto de audio al nivel objetivo especificado.\n","\n","Parámetros de entrada:\n","- audio (AudioSegment): Objeto de audio que se desea normalizar.\n","- target_dBFS (float, opcional): Nivel de volumen objetivo en decibelios relativos al nivel de referencia (dBFS).\n","\n","Salida:\n","- AudioSegment: Objeto de audio normalizado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ITpMtuXWMaZL"},"outputs":[],"source":["def normalize_audio(audio, target_dBFS=-20.0):\n","    change_in_dBFS = target_dBFS - audio.dBFS\n","    normalized_audio = audio.apply_gain(change_in_dBFS)\n","    print(\"Audio normalizado\")\n","    return normalized_audio"]},{"cell_type":"markdown","metadata":{"id":"OhfW62XdMaZL"},"source":["Aplica compresión dinámica a un objeto de audio.\n","\n","Parámetros de entrada:\n","- audio (AudioSegment): Objeto de audio al que se desea aplicar compresión.\n","- threshold (float, opcional): Umbral en decibelios a partir del cual se aplica la compresión.\n","- ratio (float, opcional): Relación de compresión que determina cuánto se reduce el volumen por encima del umbral.\n","- attack (float, opcional): Tiempo en milisegundos que tarda la compresión en activarse.\n","- release (float, opcional): Tiempo en milisegundos que tarda la compresión en desactivarse.\n","\n","Salida:\n","- AudioSegment\n","    Objeto con audio comprimido dinámicamente."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Piqms5nCMaZL"},"outputs":[],"source":["def dynamic_compression(audio, threshold=-20.0, ratio=4.0, attack=5.0, release=50.0):\n","    compressed_audio = audio.compress_dynamic_range(\n","        threshold=threshold,\n","        ratio=ratio,\n","        attack=attack,\n","        release=release\n","    )\n","    print(\"Audio comprimido dinámicamente\")\n","    return compressed_audio"]},{"cell_type":"markdown","metadata":{"id":"W92DNr2TMaZL"},"source":["Procesa todos los archivos de audio en un directorio y sus subdirectorios.\n","Aplica conversión a WAV, reducción de ruido, recorte de silencio, normalización y compresión dinámica.\n","\n","Parámetros de entrada:\n","- root_directory: str\n","    Ruta al directorio raíz que contiene los archivos de audio a procesar.\n","\n","No hay salida explícita, pero se generan archivos de audio procesados en el mismo directorio."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q5k0Dm5BMaZL"},"outputs":[],"source":["def process_audio_files(root_directory):\n","    for current_folder, subfolders, files in os.walk(root_directory):\n","        for file in files:\n","            full_path = os.path.join(current_folder, file)\n","            name, extension = os.path.splitext(file)\n","            if extension.lower() not in ['.mp3', '.aac', '.flac', '.ogg', '.m4a']:\n","                continue  # Ignora archivos que no son de audio\n","\n","            try:\n","                # Aplicar cada paso del procesamiento\n","                audio = AudioSegment.from_file(full_path)\n","                audio = reduce_noise(audio)\n","                audio = trim_silence(audio)\n","                audio = normalize_audio(audio)\n","                audio = dynamic_compression(audio)\n","\n","                # Guardar el archivo final procesado y convertido\n","                output_file = os.path.join(root_directory,\"convertido en wav\", f\"{name}_procesado.wav\")\n","                convert_to_wav(audio, output_file)\n","\n","            except Exception as e:\n","                print(f\"Error al procesar {full_path}: {e}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wUtbvVTvMaZM","outputId":"b7ee5376-c121-48eb-d57a-6f6bc6fd70d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ruido reducido\n","Silencio recortado\n","Audio normalizado\n","Audio comprimido dinámicamente\n","Exportado AudioSegment a WAV: c:\\Users\\Jesus\\Downloads\\Nueva carpeta\\Grabación_procesado.wav\n"]}],"source":["root_directory = os.getcwd()  # Obtiene el directorio actual\n","process_audio_files(root_directory)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"DataScience","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}